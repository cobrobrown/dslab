{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "referenced-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines with supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-point",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   target category  index  \n",
       "0       0    first      0  \n",
       "1       0    first      1  \n",
       "2       0    first      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>second</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>second</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>second</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target category  index  \n",
       "147       2   second    147  \n",
       "148       2   second    148  \n",
       "149       2   second    149  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "'''\n",
    "# add random noise to inputs (lower accuracy)\n",
    "df[df.columns[0]] += np.random.normal(2, 2, len(df.index))\n",
    "df[df.columns[1]] += np.random.normal(-1, 2, len(df.index))\n",
    "df[df.columns[3]] += np.random.normal(0, 2, len(df.index))\n",
    "df[df.columns[2]] += np.random.normal(0, 2, len(df.index))\n",
    "'''\n",
    "# add cateogrical data for OHE\n",
    "df['category'] = 'first'\n",
    "df.loc[df.index>int(len(df.index)/2),'category'] = 'second'\n",
    "\n",
    "# index as a feature\n",
    "df['index'] = df.index\n",
    "\n",
    "\n",
    "display(df.head(3))\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abandoned-jerusalem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(df[df.columns[:2]],df['target'])\n",
    "clf.score(df[df.columns[:2]],df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proved-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.92\n"
     ]
    }
   ],
   "source": [
    "## train pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('estimator', GradientBoostingClassifier(max_depth=3, n_estimators=100))\n",
    "    ])\n",
    "pipeline.fit(df[df.columns[:2]],df['target'])\n",
    "print('score',pipeline.score(df[df.columns[:2]],df['target']))\n",
    "pickle.dump( pipeline, open( \"pipeline.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sudden-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained scaler params:\n",
      "scale_ [0.82530129 0.43441097]\n",
      "feature_importances_ [0.72342329 0.27657671]\n",
      "\n",
      "score 0.9233333333333333\n",
      "score 0.9206666666666666\n",
      "score 0.9126666666666666\n",
      "score 0.9073333333333333\n",
      "score 0.928\n",
      "score 0.92\n",
      "score 0.92\n",
      "score 0.912\n",
      "score 0.9013333333333333\n",
      "score 0.9133333333333333\n"
     ]
    }
   ],
   "source": [
    "## load pipeline and predict on new data (10 times to see variance)\n",
    "pipeline_loaded = pickle.load( open( \"pipeline.pkl\", \"rb\" ) )\n",
    "\n",
    "# look at trained pipeline params\n",
    "print('trained scaler params:')\n",
    "print('scale_',pipeline_loaded['scaler'].scale_)\n",
    "print('feature_importances_',pipeline_loaded['estimator'].feature_importances_)\n",
    "print()\n",
    "for i in range(10):\n",
    "    df_new = df.sample(n=len(df)*10,replace=True)\n",
    "    print('score',pipeline_loaded.score(df_new[df.columns[:2]],df_new['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-swaziland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suburban-classroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.973\n"
     ]
    }
   ],
   "source": [
    "### mixed type transforms in pipeline\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "numeric_features = ['sepal length (cm)','sepal width (cm)']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['category']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "clf.fit(df[numeric_features+categorical_features], df['target'])\n",
    "print(\"model score: %.3f\" % clf.score(df[numeric_features+categorical_features], df['target']))\n",
    "pickle.dump( clf,open( \"clf.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "connected-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained scaler params:\n",
      "scale_ [0.82530129 0.43441097]\n",
      "feature_importances_ [0.49625004 0.2107349  0.15763196 0.13538309]\n",
      "\n",
      "score 0.97\n",
      "score 0.9786666666666667\n",
      "score 0.9706666666666667\n",
      "score 0.9673333333333334\n",
      "score 0.9693333333333334\n",
      "score 0.9746666666666667\n",
      "score 0.97\n",
      "score 0.974\n",
      "score 0.9726666666666667\n",
      "score 0.9726666666666667\n"
     ]
    }
   ],
   "source": [
    "## load pipeline and predict on new data (10 times to see variance)\n",
    "clf_loaded = pickle.load( open( \"clf.pkl\", \"rb\" ) )\n",
    "\n",
    "# look at trained pipeline params\n",
    "print('trained scaler params:')\n",
    "print('scale_',clf_loaded['preprocessor'].named_transformers_['num']['scaler'].scale_)\n",
    "print('feature_importances_',clf_loaded['classifier'].feature_importances_)\n",
    "print()\n",
    "for i in range(10):\n",
    "    df_new = df.sample(n=len(df)*10,replace=True)\n",
    "    print('score',clf_loaded.score(df_new[numeric_features+categorical_features],df_new['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-oxford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "municipal-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "### custom transforms\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PositionalSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, positions):\n",
    "        self.positions = positions\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array(X)[:, self.positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-latin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
